{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 17777,
          "databundleVersionId": 869809,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 29852,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import string\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer,HashingVectorizer\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "trusted": true,
        "id": "PgtVl_dsgawi"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "drive.mount('/content/drive')\n",
        "%cd \"/content/drive/My Drive/Colab Notebooks/mental-health-codes\"\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/mental-health-codes')\n",
        "#import utilities as ut\n",
        "\n",
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgrCzh9AhK4Y",
        "outputId": "5e2cf2cf-8f59-485b-e5d9-21189c5beebd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/Colab Notebooks/mental-health-codes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"Mental-Health-Twitter.csv\"\n",
        "df = pd.read_csv(path).drop(columns=['Unnamed: 0', \"post_created\", \"user_id\"])\n",
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YBYRRb5ehnTI",
        "outputId": "a0cd29e0-a29e-4355-e03e-b564ad1c4eb1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              post_id                                          post_text  \\\n",
              "0  637894677824413696  It's just over 2 years since I was diagnosed w...   \n",
              "1  637890384576778240  It's Sunday, I need a break, so I'm planning t...   \n",
              "2  637749345908051968  Awake but tired. I need to sleep but my brain ...   \n",
              "3  637696421077123073  RT @SewHQ: #Retro bears make perfect gifts and...   \n",
              "4  637696327485366272  It’s hard to say whether packing lists are mak...   \n",
              "\n",
              "   followers  friends  favourites  statuses  retweets  label  \n",
              "0         84      211         251       837         0      1  \n",
              "1         84      211         251       837         1      1  \n",
              "2         84      211         251       837         0      1  \n",
              "3         84      211         251       837         2      1  \n",
              "4         84      211         251       837         1      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f44e5642-3c8a-44fa-9045-1a8f43d6b408\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>post_id</th>\n",
              "      <th>post_text</th>\n",
              "      <th>followers</th>\n",
              "      <th>friends</th>\n",
              "      <th>favourites</th>\n",
              "      <th>statuses</th>\n",
              "      <th>retweets</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>637894677824413696</td>\n",
              "      <td>It's just over 2 years since I was diagnosed w...</td>\n",
              "      <td>84</td>\n",
              "      <td>211</td>\n",
              "      <td>251</td>\n",
              "      <td>837</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>637890384576778240</td>\n",
              "      <td>It's Sunday, I need a break, so I'm planning t...</td>\n",
              "      <td>84</td>\n",
              "      <td>211</td>\n",
              "      <td>251</td>\n",
              "      <td>837</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>637749345908051968</td>\n",
              "      <td>Awake but tired. I need to sleep but my brain ...</td>\n",
              "      <td>84</td>\n",
              "      <td>211</td>\n",
              "      <td>251</td>\n",
              "      <td>837</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>637696421077123073</td>\n",
              "      <td>RT @SewHQ: #Retro bears make perfect gifts and...</td>\n",
              "      <td>84</td>\n",
              "      <td>211</td>\n",
              "      <td>251</td>\n",
              "      <td>837</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>637696327485366272</td>\n",
              "      <td>It’s hard to say whether packing lists are mak...</td>\n",
              "      <td>84</td>\n",
              "      <td>211</td>\n",
              "      <td>251</td>\n",
              "      <td>837</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f44e5642-3c8a-44fa-9045-1a8f43d6b408')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f44e5642-3c8a-44fa-9045-1a8f43d6b408 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f44e5642-3c8a-44fa-9045-1a8f43d6b408');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b09a5f14-29b5-450a-ab3c-56b66228cbde\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b09a5f14-29b5-450a-ab3c-56b66228cbde')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b09a5f14-29b5-450a-ab3c-56b66228cbde button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20000,\n  \"fields\": [\n    {\n      \"column\": \"post_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 170839623650185920,\n        \"min\": 3555966067,\n        \"max\": 819457358145273856,\n        \"num_unique_values\": 19881,\n        \"samples\": [\n          286928178855940096,\n          811771009162354688,\n          818137361733349380\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"post_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19488,\n        \"samples\": [\n          \"@Megafighter3 Like..we weren't even arguing about anything. I was just being silly and she thought I was being condescending.\",\n          \"Eating healthy makes you feel so good about yourself\\ud83d\\ude1c\\ud83c\\udf49\\ud83c\\udf53\\ud83c\\udf52\\ud83c\\udf4d\",\n          \"In Opinion: What Trump should say but won\\u2019t about Putin\\u2019s election cyberhack https://t.co/VKWeSn9mOC   I'm dreaming, where the voices, loud!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"followers\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1899,\n        \"min\": 0,\n        \"max\": 28614,\n        \"num_unique_values\": 69,\n        \"samples\": [\n          104,\n          84,\n          434\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"friends\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1834,\n        \"min\": 0,\n        \"max\": 28514,\n        \"num_unique_values\": 70,\n        \"samples\": [\n          247,\n          211,\n          988\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"favourites\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8393,\n        \"min\": 0,\n        \"max\": 39008,\n        \"num_unique_values\": 66,\n        \"samples\": [\n          704,\n          2228,\n          251\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"statuses\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 140778,\n        \"min\": 3,\n        \"max\": 1063601,\n        \"num_unique_values\": 71,\n        \"samples\": [\n          1300,\n          837,\n          6694\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"retweets\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15119,\n        \"min\": 0,\n        \"max\": 839540,\n        \"num_unique_values\": 1706,\n        \"samples\": [\n          42,\n          733,\n          128574\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train-test data split"
      ],
      "metadata": {
        "id": "5hauFCRmFQEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.post_text.values\n",
        "y = df.label.values\n",
        "\n",
        "X_train, X_val, y_train, y_val =\\\n",
        "train_test_split(X, y, test_size=0.2, random_state=666)"
      ],
      "metadata": {
        "id": "XyQFnRTkh4Rv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align='center'><font size=\"6\" color=\"#F39C12\">Getting started with NLP-Feature Vectors</font></div>\n",
        "\n",
        "<hr>\n",
        "\n",
        "\n",
        "<p style='text-align:justify'><b>Key Objectives:</b>This notebook comes as a second part to the <b>[Getting started with NLP Notebooks](https://www.kaggle.com/parulpandey/getting-started-with-nlp-a-general-intro)</b>.In this notebook we shall study the various ways of vectorizing text data.Vectorization converts text data into feature vectors.</p>\n",
        "\n"
      ],
      "metadata": {
        "id": "kjbc5KWWgawj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the dataset"
      ],
      "metadata": {
        "id": "r21SeAFigawk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Vectorization Methods\n",
        "\n",
        "There are many methods to vctorize text, but in this notebook I shall discuss few of them:"
      ],
      "metadata": {
        "id": "U9rcnfkCgawl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.Countvectorizer\n",
        "\n",
        "The [Scikit-Learn's CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary.\n",
        "\n",
        "![](https://imgur.com/xxErhnB.png)\n",
        "\n",
        "We take a dataset and convert it into a corpus. Then we create a vocabulary of all the unique words in the corpus. Using this vocabulary, we can then  create a feature vector of the count of the words. Let's see this through a simple example. Let's say we have a corpus containing two sentences as follows"
      ],
      "metadata": {
        "id": "vOQO7rcjgawl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = ['Feeling worried, even though you actually have a God who is ready to help you in any case.', 'Why is my school so different? the others have passed why do i still have assignments and exams']"
      ],
      "metadata": {
        "trusted": true,
        "id": "1rVtoYtEgawl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(sentences)\n",
        "vectorizer.vocabulary_"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1r5VMOZxgawm",
        "outputId": "428eae1b-f1f0-4eb6-cc81-8f100e76993b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'feeling': 9,\n",
              " 'worried': 27,\n",
              " 'even': 7,\n",
              " 'though': 23,\n",
              " 'you': 28,\n",
              " 'actually': 0,\n",
              " 'have': 11,\n",
              " 'god': 10,\n",
              " 'who': 25,\n",
              " 'is': 14,\n",
              " 'ready': 18,\n",
              " 'to': 24,\n",
              " 'help': 12,\n",
              " 'in': 13,\n",
              " 'any': 2,\n",
              " 'case': 4,\n",
              " 'why': 26,\n",
              " 'my': 15,\n",
              " 'school': 19,\n",
              " 'so': 20,\n",
              " 'different': 5,\n",
              " 'the': 22,\n",
              " 'others': 16,\n",
              " 'passed': 17,\n",
              " 'do': 6,\n",
              " 'still': 21,\n",
              " 'assignments': 3,\n",
              " 'and': 1,\n",
              " 'exams': 8}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting all the sentences to arrays\n",
        "vectorizer.transform(sentences).toarray()"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1DAhUHvgawm",
        "outputId": "63779e35-53fe-4775-ce15-8f351e77daf8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "        0, 1, 1, 1, 0, 1, 2],\n",
              "       [0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 2, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
              "        1, 0, 0, 0, 2, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, a scikit learn Count vectorizer can perform the following opertions over a text corpus:\n",
        "\n",
        "- Encoding via utf-8\n",
        "- converts text to lowercase\n",
        "- Tokenizes text using word level tokenization\n",
        "\n",
        "CountVectorizer has a number of parameters. Let's look at some of them :"
      ],
      "metadata": {
        "id": "mlAWDhjUgawm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Stopword\n",
        "\n",
        "Sometimes, some extremely common words which would appear to be of little value in helping select documents matching a user need are excluded from the vocabulary entirely. These words are called stop words. If `stop_word` parameter is specified with a list of stopwords, they will be removed from the vocabulary. Here I'll use the stopwords from NLTK but we can also specify custom stopwords too.\n"
      ],
      "metadata": {
        "id": "6ljmMaTfgawm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stopwords = stopwords.words('english')\n",
        "\n",
        "count_vectorizer = CountVectorizer(stop_words = stopwords)\n",
        "count_vectorizer.fit(X_train)\n",
        "\n",
        "train_vectors = count_vectorizer.transform(X_train)\n",
        "test_vectors = count_vectorizer.transform(X_val)\n",
        "\n",
        "train_vectors.shape"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9NLTDZFgawm",
        "outputId": "a06b7073-3150-48c9-dfb6-74219b5f6843"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16000, 27756)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "See how the columns have reduced from 21637 to 21498. This is because some of the stopwords were removed."
      ],
      "metadata": {
        "id": "KvHyvq9Zgawm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 MIN_DF and MAX_DF parameter\n",
        "\n",
        "`MIN_DF` lets you ignore those terms that appear rarely in a corpus. In other words, if `MIN_df`is 2, it  means that a word has to occur at least two documents to be considered useful.\n",
        "\n",
        "`MAX_DF` on the other hand, ignores terms that have a document frequency strictly higher than the given threshold.These will be words which appear a lot of documents.\n",
        "\n",
        "This means we can eliminate those words that are either rare or appear too frequently in a corpus.\n",
        "\n",
        "When mentioned in absolute values i.e 1,2, etc, the value means if the word appears in 1 or 2 documents. However, when given in float, eg 30%, it means it appears in 30% of the documents."
      ],
      "metadata": {
        "id": "s-KKsB2hgawn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_vectorizer = CountVectorizer(stop_words = stopwords, min_df=2 ,max_df=0.8)\n",
        "count_vectorizer.fit(X_train)\n",
        "\n",
        "train_vectors = count_vectorizer.transform(X_train)\n",
        "test_vectors = count_vectorizer.transform(X_val)"
      ],
      "metadata": {
        "trusted": true,
        "id": "IJisGEchgawn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3.Custom Preprocesser\n",
        "\n",
        "We can also preprocess the text by passing it as an argument to countvectorizer. The following options are avialable:\n",
        "\n",
        "- strip_accents - This removes any accents from the text during the preprocessing step.\n",
        "- lowercase -  which is default set as true but can be set to False if lowercasing isnot desired\n",
        "- preprocessor - we can create our custom preprocessor and set this argument to that.\n",
        "\n"
      ],
      "metadata": {
        "id": "jfOQg6qlgawn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a custom preprocessor that lowercases, removes special characters, removes hyperlinks and punctuation\n",
        "\n",
        "def custom_preprocessor(text):\n",
        "    '''\n",
        "    Make text lowercase, remove text in square brackets,remove links,remove special characters\n",
        "    and remove words containing numbers.\n",
        "    '''\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub(\"\\\\W\",\" \",text) # remove special chars\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "trusted": true,
        "id": "sbOiSBu9gawn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# World level unigrams and bigrams\n",
        "count_vectorizer = CountVectorizer(stop_words=\"english\", preprocessor=custom_preprocessor, analyzer='word',\n",
        "                            ngram_range=(1, 2), max_df=1.0, min_df=1, max_features=None)\n",
        "\n",
        "train_vectors = count_vectorizer.fit_transform(list(X_train))\n",
        "test_vectors = count_vectorizer.transform(list(X_val))\n",
        "list(count_vectorizer.vocabulary_)[:10]"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_15jSsjagawn",
        "outputId": "2edf0358-1316-43a8-cd51-815b47b6c4fb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['lehudos',\n",
              " 'dis',\n",
              " 'real',\n",
              " 'weapon',\n",
              " 'yo',\n",
              " 'cosplayyy',\n",
              " 'lehudos dis',\n",
              " 'dis real',\n",
              " 'real weapon',\n",
              " 'weapon yo']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4. N-Grams and analyzer parameter\n",
        "\n",
        "This paramneter specifies the upper and lower limit for the range of words/characters to be extracted from text. The following n-grams range stand for:\n",
        "(1,1) - unigrams  eg 'United'\n",
        "(1,2) - unigrams and bigrams eg - 'United', 'United States'\n",
        "(2, 2)- only bigrams etc eg 'United States)\n"
      ],
      "metadata": {
        "id": "P1SVoSbcgawn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# character level bigrams\n",
        "\n",
        "count_vectorizer = CountVectorizer(stop_words=\"english\", analyzer='char_wb', preprocessor=custom_preprocessor,\n",
        "                            ngram_range=(2, 2), max_df=2, min_df=2, max_features=None)\n",
        "\n",
        "train_vectors = count_vectorizer.fit_transform(list(X_train))\n",
        "test_vectors = count_vectorizer.transform(list(X_val))\n",
        "\n",
        "print(list(count_vectorizer.vocabulary_)[:20])"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FU0XASIDgawn",
        "outputId": "2f1435fa-55e7-4c76-824f-6083d49c5397"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ké', 'ém', 'â ', ' 松', '松元', '元 ', ' 彰', '彰 ', ' 森', '森 ', ' 和', '和夫', '夫 ', 'lè', 'è ', ' ツ', 'ツ ', 'hé', ' 原', '原宿']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a Baseline Model using Countvectorizer"
      ],
      "metadata": {
        "id": "uHZjfRTVgawn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "count_vectorizer = CountVectorizer(token_pattern=r'\\w{1,}',\n",
        "                   ngram_range=(1, 2), stop_words = stopwords,preprocessor=custom_preprocessor)\n",
        "count_vectorizer .fit(X_train)\n",
        "\n",
        "train_vectors = count_vectorizer.transform(X_train)\n",
        "test_vectors = count_vectorizer.transform(X_val)"
      ],
      "metadata": {
        "trusted": true,
        "id": "-j2UftDFgawn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression(C=1.0)\n",
        "scores = model_selection.cross_val_score(clf, train_vectors, y_train, cv=5, scoring=\"f1\")\n",
        "scores"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQjkLmZ-gawn",
        "outputId": "024719a3-604a-4179-8750-7b917aab20cf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.86811146, 0.85696633, 0.86278138, 0.86800618, 0.85910224])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting a simple Logistic Regression on Counts\n",
        "clf.fit(train_vectors, y_train)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "3PCzn2augawn",
        "outputId": "561a85a7-afd5-4be5-894d-71da46b7f0a4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.score(test_vectors, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuKwSMIh_38S",
        "outputId": "72338f37-313e-40d4-e28e-5b03f161c373"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.85325"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This gets me a score of 0.80777 on the Public LB, which isn't bad with simple Logistic Regression model."
      ],
      "metadata": {
        "id": "rWCogxTdgawn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.TF-IDF Vectorizer\n",
        "\n",
        "![](https://imgur.com/J5lS7kX.png)\n",
        "\n",
        "In the CountVectorizer, we use the counts of the words, in TFIDF we take the relative importance of that term in the entire corpus. TFIDF is composed of two words: TF and IDF.\n",
        "**TF** stands for the normalized  term frequency. Term Frequency is a scoring of the frequency of the word in the current document.`TF = (Number of times term t appears in a document)/(Number of terms in the document)`\n",
        "\n",
        "**IDF** or Inverse Document Frequency: is a scoring of how rare the word is across documents. `IDF = 1+log(N/n)`, where N is the number of documents and n is the number of documents a term t has appeared in.TF-IDF weight is often used in information retrieval and text mining. This weight is a statistical measure used to evaluate how important a word is to a document in a collection or corpus\n",
        "\n"
      ],
      "metadata": {
        "id": "GE5czMMPgawn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TFIDF can be generated at word, character or even N gram level."
      ],
      "metadata": {
        "id": "NbvacnXngawo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# word level\n",
        "tfidf = TfidfVectorizer(analyzer='word',token_pattern=r'\\w{1,}',max_features=5000)\n",
        "train_tfidf = tfidf.fit_transform(X_train)\n",
        "test_tfidf = tfidf.transform(X_val)"
      ],
      "metadata": {
        "trusted": true,
        "id": "DrTDx-OBgawo"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ngram level\n",
        "tfidf = TfidfVectorizer(analyzer='word',ngram_range=(2,3),token_pattern=r'\\w{1,}',max_features=5000)\n",
        "train_tfidf = tfidf.fit_transform(X_train)\n",
        "test_tfidf = tfidf.transform(X_val)"
      ],
      "metadata": {
        "trusted": true,
        "id": "K_hrAZ7mgawo"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# characters level\n",
        "tfidf = TfidfVectorizer(analyzer='char',ngram_range=(2,3),token_pattern=r'\\w{1,}',max_features=5000)\n",
        "train_tfidf = tfidf.fit_transform(X_train)\n",
        "test_tfidf = tfidf.transform(X_val)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "FibotJZZgawo"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a Baseline Model using TFIDF"
      ],
      "metadata": {
        "id": "QECjvQ5Vgawo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer( min_df=3,  max_features=None,analyzer='word',token_pattern=r'\\w{1,}',\n",
        "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
        "            stop_words = stopwords)\n",
        "\n",
        "train_tfidf = tfidf.fit_transform(X_train)\n",
        "test_tfidf = tfidf.transform(X_val)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "QsWmqS2kgawo"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression(C=1.0)\n",
        "scores = model_selection.cross_val_score(clf, train_tfidf, y_train, cv=5, scoring=\"f1\")\n",
        "scores"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tr-g7-qcgawo",
        "outputId": "6977586c-678a-463f-b45f-e05cb1c85cac"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.87027708, 0.85786164, 0.86464771, 0.86689851, 0.86335404])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting a simple Logistic Regression on TFIDF\n",
        "clf.fit(train_tfidf, y_train)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "rMBKHwiKgawo",
        "outputId": "7ff27a94-357b-415a-aaae-faf2c1401f77"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.Hashing Vectorizer\n",
        "\n",
        "![](https://imgur.com/e3GRaHn.png)\n",
        "\n",
        "Hashing Vectorizer is yet another technique for vectorizing a collection of text documents. So why do we need yet another technique when we already have so many already. Well, the reason is that,both CountVectorizer and TF-IDF result in storing the entire vocabulary dictionary in memory i.e the number of unique tokens.This could be challenging in scenarios when the token vocabulary becomes very large, to the order of millions.\n"
      ],
      "metadata": {
        "id": "c-eksnylgawo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hash_vectorizer = HashingVectorizer(n_features=10000,norm=None,alternate_sign=False)\n",
        "hash_vectorizer.fit(X_train)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "Z2_PUUabgawo",
        "outputId": "fe4ecea0-4eb5-4f6d-f590-06447e0b7a42"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HashingVectorizer(alternate_sign=False, n_features=10000, norm=None)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HashingVectorizer(alternate_sign=False, n_features=10000, norm=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HashingVectorizer</label><div class=\"sk-toggleable__content\"><pre>HashingVectorizer(alternate_sign=False, n_features=10000, norm=None)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_vectors = hash_vectorizer.transform(X_train)\n",
        "test_vectors = hash_vectorizer.transform(X_val)"
      ],
      "metadata": {
        "trusted": true,
        "id": "3plCE2swgawo"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_vectors[0])"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3scZOV7ogaws",
        "outputId": "391195f2-9149-4d8c-e8b8-be1bf90029a0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 306)\t1.0\n",
            "  (0, 2657)\t1.0\n",
            "  (0, 3124)\t1.0\n",
            "  (0, 4930)\t1.0\n",
            "  (0, 5411)\t1.0\n",
            "  (0, 6417)\t1.0\n",
            "  (0, 9212)\t1.0\n",
            "  (0, 9988)\t1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression(C=1.0)\n",
        "scores = model_selection.cross_val_score(clf, train_vectors, y_train, cv=5, scoring=\"f1\")\n",
        "scores"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naPtK6VNgaws",
        "outputId": "d68aa554-cd77-422e-fee5-76499a7e7157"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.86418982, 0.84348641, 0.85164494, 0.85192187, 0.85356696])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting a simple Logistic Regression on TFIDF\n",
        "clf.fit(train_vectors, y_train)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "4vDG5fMegaws",
        "outputId": "71182ee1-e3ec-479c-d8b8-9b10e76037b7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}
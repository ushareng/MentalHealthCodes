{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install nltk\n",
        "%pip install spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4nwrZ79v1c0",
        "outputId": "259b6dbf-94a7-4424-836a-4d14d56dfa2d"
      },
      "id": "v4nwrZ79v1c0",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.8.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.6.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download Stopwords"
      ],
      "metadata": {
        "id": "9WrOEyksw5Qb"
      },
      "id": "9WrOEyksw5Qb"
    },
    {
      "cell_type": "code",
      "source": [
        "# import the existing word and sentence tokenizing\n",
        "# libraries\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "print(stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKs9olNavqw8",
        "outputId": "313c0f17-86b8-411a-8fc5-e71d3fe80d9c"
      },
      "id": "ZKs9olNavqw8",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"that'll\", 'who', 'he', \"needn't\", 'for', 'what', 'before', 'my', 'where', 'about', 'am', 'whom', 'can', 'during', 'them', 'should', \"aren't\", 'wasn', 'shan', 'few', \"wouldn't\", 'will', \"shan't\", \"should've\", 'yourself', 'were', 'myself', 'off', 'out', 'being', 'from', 'ain', 'won', \"didn't\", 'ourselves', 'and', 'our', 'too', 'both', \"mightn't\", 'its', 'until', 'below', 'but', 'as', 'these', 'above', 'over', 'haven', 'hers', 'mightn', 'does', 'most', 'with', 'same', 'his', 'had', 'mustn', 'you', 'under', 'here', 'yours', 'this', 'theirs', 'between', 'such', 'down', 'themselves', 'hadn', 'an', 'now', 'm', 'while', \"mustn't\", \"you're\", 'when', 'isn', 'to', 'been', 'very', 'after', 'a', 'that', 'do', 'up', 'once', 'wouldn', \"doesn't\", 'she', 'couldn', 'shouldn', 'was', 'the', 'aren', \"hasn't\", 'her', 'no', 'then', 'on', 'some', 're', 'd', 's', 'against', 'needn', 'they', 'o', \"hadn't\", 've', 'own', 'by', 'didn', 't', 'only', \"it's\", \"you've\", 'or', \"shouldn't\", 'nor', \"don't\", 'him', 'ours', 'in', \"you'd\", \"won't\", 'be', \"you'll\", 'again', \"couldn't\", 'because', 'i', \"wasn't\", 'yourselves', 'there', 'at', 'don', 'those', 'further', \"haven't\", 'me', 'any', 'herself', 'll', 'so', 'which', 'himself', 'has', 'did', 'have', 'all', 'having', 'ma', 'not', 'itself', 'other', 'just', 'into', 'how', 'it', 'their', 'if', 'more', 'weren', \"weren't\", 'is', 'doesn', 'each', \"she's\", 'hasn', 'doing', 'of', 'through', \"isn't\", 'your', 'we', 'y', 'are', 'than', 'why'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Convert to lowercase and remove numericals, stopwords from Text"
      ],
      "metadata": {
        "id": "9WV4YeixwiwK"
      },
      "id": "9WV4YeixwiwK"
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load spaCy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Sample text\n",
        "text = \"I'm a  very empathetic person and I always try 2 be kind and loving to people However, I'm constantly worried that I'm not doing it right, or that the things I enjoy and the way I think/act is offensive and not very caring. I'm fine with changing how I behave if what I'm doing bothers people, but I got so overwhelmed and frustrated on what if I I am doing is offensive to someone. I feel unknowingly I may have hurt someone, and the thought makes me feel guilt and makes me feel that I can't enjoy my life very much. I want to be courteous to everyone and respect things that bother them and then not do/say those things, but I feel like I wearing myself out by constantly overthinking of myself.\"\n",
        "modified_str = ''.join([i for i in text if not i.isdigit()])\n",
        "\n",
        "\n",
        "# Process the text using spaCy\n",
        "doc = nlp(modified_str)\n",
        "\n",
        "# Remove stopwords\n",
        "filtered_words = [token.text.lower() for token in doc if not token.is_stop]\n",
        "\n",
        "\n",
        "# Join the filtered words to form a clean text\n",
        "clean_text = ' '.join(filtered_words)\n",
        "\n",
        "print(\"Original Text:\", text)\n",
        "print(\"Text after Stopword Removal:\", clean_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZHC9gglvuba",
        "outputId": "f40064dc-ece0-4eb6-d0db-0807bd2cae53"
      },
      "id": "KZHC9gglvuba",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: I'm a  very empathetic person and I always try 2 be kind and loving to people However, I'm constantly worried that I'm not doing it right, or that the things I enjoy and the way I think/act is offensive and not very caring. I'm fine with changing how I behave if what I'm doing bothers people, but I got so overwhelmed and frustrated on what if I I am doing is offensive to someone. I feel unknowingly I may have hurt someone, and the thought makes me feel guilt and makes me feel that I can't enjoy my life very much. I want to be courteous to everyone and respect things that bother them and then not do/say those things, but I feel like I wearing myself out by constantly overthinking of myself.\n",
            "Text after Stopword Removal:   empathetic person try   kind loving people , constantly worried right , things enjoy way think / act offensive caring . fine changing behave bothers people , got overwhelmed frustrated offensive . feel unknowingly hurt , thought makes feel guilt makes feel enjoy life . want courteous respect things bother / things , feel like wearing constantly overthinking .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenize the given Text"
      ],
      "metadata": {
        "id": "ESRB0L_TwuDA"
      },
      "id": "ESRB0L_TwuDA"
    },
    {
      "cell_type": "code",
      "source": [
        "#text = \"I'm a very empathetic person and I always try be kind and loving to people However, I'm constantly worried that I'm not doing it right, or that the things I enjoy and the way I think/act is offensive and not very caring. I'm fine with changing how I behave if what I'm doing bothers people, but I got so overwhelmed and frustrated on what if I I am doing is offensive to someone. I feel unknowingly I may have hurt someone, and the thought makes me feel guilt and makes me feel that I can't enjoy my life very much. I want to be courteous to everyone and respect things that bother them and then not do/say those things, but I feel like I wearing myself out by constantly overthinking of myself.\"\n",
        "tokenized = sent_tokenize(clean_text)\n",
        "print(tokenized)\n",
        "wordsList = word_tokenize(clean_text)\n",
        "print(wordsList)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oV-ZQY8qvKjC",
        "outputId": "6eb80194-b0cd-4a2c-a9c5-9e72a004e668"
      },
      "id": "oV-ZQY8qvKjC",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['  empathetic person try   kind loving people , constantly worried right , things enjoy way think / act offensive caring .', 'fine changing behave bothers people , got overwhelmed frustrated offensive .', 'feel unknowingly hurt , thought makes feel guilt makes feel enjoy life .', 'want courteous respect things bother / things , feel like wearing constantly overthinking .']\n",
            "['empathetic', 'person', 'try', 'kind', 'loving', 'people', ',', 'constantly', 'worried', 'right', ',', 'things', 'enjoy', 'way', 'think', '/', 'act', 'offensive', 'caring', '.', 'fine', 'changing', 'behave', 'bothers', 'people', ',', 'got', 'overwhelmed', 'frustrated', 'offensive', '.', 'feel', 'unknowingly', 'hurt', ',', 'thought', 'makes', 'feel', 'guilt', 'makes', 'feel', 'enjoy', 'life', '.', 'want', 'courteous', 'respect', 'things', 'bother', '/', 'things', ',', 'feel', 'like', 'wearing', 'constantly', 'overthinking', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Do POS Tagging"
      ],
      "metadata": {
        "id": "O9QR439Aw_rD"
      },
      "id": "O9QR439Aw_rD"
    },
    {
      "cell_type": "code",
      "source": [
        "for i in tokenized:\n",
        "\n",
        "    # Word tokenizers is used to find the words\n",
        "    # and punctuation in a string\n",
        "    #wordsList = nltk.word_tokenize(i)\n",
        "\n",
        "    # removing stop words from wordList\n",
        "    wordsList = [w for w in wordsList if not w in stop_words]\n",
        "\n",
        "    #  Using a Tagger. Which is part-of-speech\n",
        "    # tagger or POS-tagger.\n",
        "    pos_tagged = nltk.pos_tag(wordsList)\n",
        "\n",
        "    print(pos_tagged)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdHKvxKyxGxB",
        "outputId": "6cd9aea7-dc55-401b-a30b-00d9e8dceedb"
      },
      "id": "QdHKvxKyxGxB",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('empathetic', 'JJ'), ('person', 'NN'), ('try', 'VB'), ('kind', 'NN'), ('loving', 'VBG'), ('people', 'NNS'), (',', ','), ('constantly', 'RB'), ('worried', 'VBD'), ('right', 'JJ'), (',', ','), ('things', 'NNS'), ('enjoy', 'VBP'), ('way', 'NN'), ('think', 'VBP'), ('/', 'NNP'), ('act', 'NN'), ('offensive', 'JJ'), ('caring', 'NN'), ('.', '.'), ('fine', 'JJ'), ('changing', 'VBG'), ('behave', 'JJ'), ('bothers', 'NNS'), ('people', 'NNS'), (',', ','), ('got', 'VBD'), ('overwhelmed', 'JJ'), ('frustrated', 'JJ'), ('offensive', 'NN'), ('.', '.'), ('feel', 'VB'), ('unknowingly', 'RB'), ('hurt', 'VBN'), (',', ','), ('thought', 'VBN'), ('makes', 'VBZ'), ('feel', 'NN'), ('guilt', 'JJ'), ('makes', 'VBZ'), ('feel', 'NN'), ('enjoy', 'JJ'), ('life', 'NN'), ('.', '.'), ('want', 'VBP'), ('courteous', 'JJ'), ('respect', 'JJ'), ('things', 'NNS'), ('bother', 'RB'), ('/', 'JJ'), ('things', 'NNS'), (',', ','), ('feel', 'VBP'), ('like', 'IN'), ('wearing', 'VBG'), ('constantly', 'RB'), ('overthinking', 'VBG'), ('.', '.')]\n",
            "[('empathetic', 'JJ'), ('person', 'NN'), ('try', 'VB'), ('kind', 'NN'), ('loving', 'VBG'), ('people', 'NNS'), (',', ','), ('constantly', 'RB'), ('worried', 'VBD'), ('right', 'JJ'), (',', ','), ('things', 'NNS'), ('enjoy', 'VBP'), ('way', 'NN'), ('think', 'VBP'), ('/', 'NNP'), ('act', 'NN'), ('offensive', 'JJ'), ('caring', 'NN'), ('.', '.'), ('fine', 'JJ'), ('changing', 'VBG'), ('behave', 'JJ'), ('bothers', 'NNS'), ('people', 'NNS'), (',', ','), ('got', 'VBD'), ('overwhelmed', 'JJ'), ('frustrated', 'JJ'), ('offensive', 'NN'), ('.', '.'), ('feel', 'VB'), ('unknowingly', 'RB'), ('hurt', 'VBN'), (',', ','), ('thought', 'VBN'), ('makes', 'VBZ'), ('feel', 'NN'), ('guilt', 'JJ'), ('makes', 'VBZ'), ('feel', 'NN'), ('enjoy', 'JJ'), ('life', 'NN'), ('.', '.'), ('want', 'VBP'), ('courteous', 'JJ'), ('respect', 'JJ'), ('things', 'NNS'), ('bother', 'RB'), ('/', 'JJ'), ('things', 'NNS'), (',', ','), ('feel', 'VBP'), ('like', 'IN'), ('wearing', 'VBG'), ('constantly', 'RB'), ('overthinking', 'VBG'), ('.', '.')]\n",
            "[('empathetic', 'JJ'), ('person', 'NN'), ('try', 'VB'), ('kind', 'NN'), ('loving', 'VBG'), ('people', 'NNS'), (',', ','), ('constantly', 'RB'), ('worried', 'VBD'), ('right', 'JJ'), (',', ','), ('things', 'NNS'), ('enjoy', 'VBP'), ('way', 'NN'), ('think', 'VBP'), ('/', 'NNP'), ('act', 'NN'), ('offensive', 'JJ'), ('caring', 'NN'), ('.', '.'), ('fine', 'JJ'), ('changing', 'VBG'), ('behave', 'JJ'), ('bothers', 'NNS'), ('people', 'NNS'), (',', ','), ('got', 'VBD'), ('overwhelmed', 'JJ'), ('frustrated', 'JJ'), ('offensive', 'NN'), ('.', '.'), ('feel', 'VB'), ('unknowingly', 'RB'), ('hurt', 'VBN'), (',', ','), ('thought', 'VBN'), ('makes', 'VBZ'), ('feel', 'NN'), ('guilt', 'JJ'), ('makes', 'VBZ'), ('feel', 'NN'), ('enjoy', 'JJ'), ('life', 'NN'), ('.', '.'), ('want', 'VBP'), ('courteous', 'JJ'), ('respect', 'JJ'), ('things', 'NNS'), ('bother', 'RB'), ('/', 'JJ'), ('things', 'NNS'), (',', ','), ('feel', 'VBP'), ('like', 'IN'), ('wearing', 'VBG'), ('constantly', 'RB'), ('overthinking', 'VBG'), ('.', '.')]\n",
            "[('empathetic', 'JJ'), ('person', 'NN'), ('try', 'VB'), ('kind', 'NN'), ('loving', 'VBG'), ('people', 'NNS'), (',', ','), ('constantly', 'RB'), ('worried', 'VBD'), ('right', 'JJ'), (',', ','), ('things', 'NNS'), ('enjoy', 'VBP'), ('way', 'NN'), ('think', 'VBP'), ('/', 'NNP'), ('act', 'NN'), ('offensive', 'JJ'), ('caring', 'NN'), ('.', '.'), ('fine', 'JJ'), ('changing', 'VBG'), ('behave', 'JJ'), ('bothers', 'NNS'), ('people', 'NNS'), (',', ','), ('got', 'VBD'), ('overwhelmed', 'JJ'), ('frustrated', 'JJ'), ('offensive', 'NN'), ('.', '.'), ('feel', 'VB'), ('unknowingly', 'RB'), ('hurt', 'VBN'), (',', ','), ('thought', 'VBN'), ('makes', 'VBZ'), ('feel', 'NN'), ('guilt', 'JJ'), ('makes', 'VBZ'), ('feel', 'NN'), ('enjoy', 'JJ'), ('life', 'NN'), ('.', '.'), ('want', 'VBP'), ('courteous', 'JJ'), ('respect', 'JJ'), ('things', 'NNS'), ('bother', 'RB'), ('/', 'JJ'), ('things', 'NNS'), (',', ','), ('feel', 'VBP'), ('like', 'IN'), ('wearing', 'VBG'), ('constantly', 'RB'), ('overthinking', 'VBG'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Obtaining the stem words â€“ Lemmatization"
      ],
      "metadata": {
        "id": "MfYi5KwD0dH2"
      },
      "id": "MfYi5KwD0dH2"
    },
    {
      "cell_type": "code",
      "source": [
        "# POS_TAGGER_FUNCTION : TYPE 1\n",
        "def pos_tagger(nltk_tag):\n",
        "    if nltk_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif nltk_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif nltk_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif nltk_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "mQ1QPpkQ3zbZ"
      },
      "id": "mQ1QPpkQ3zbZ",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "#Custom pos_tagger function to make things simpler to understand.\n",
        "wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), pos_tagged))\n",
        "print(wordnet_tagged)\n",
        "\n",
        "lemmatized_sentence = []\n",
        "for word, tag in wordnet_tagged:\n",
        "    if tag is None:\n",
        "        # if there is no available tag, append the token as is\n",
        "        lemmatized_sentence.append(word)\n",
        "    else:\n",
        "        # else use the tag to lemmatize the token\n",
        "        lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
        "lemmatized_sentence = \" \".join(lemmatized_sentence)\n",
        "\n",
        "print(\"Lemmatized Sentence\", lemmatized_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIEhhqVj3WXz",
        "outputId": "a963a794-03f0-4b0b-b6de-4f174e1b1424"
      },
      "id": "fIEhhqVj3WXz",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('empathetic', 'a'), ('person', 'n'), ('try', 'v'), ('kind', 'n'), ('loving', 'v'), ('people', 'n'), (',', None), ('constantly', 'r'), ('worried', 'v'), ('right', 'a'), (',', None), ('things', 'n'), ('enjoy', 'v'), ('way', 'n'), ('think', 'v'), ('/', 'n'), ('act', 'n'), ('offensive', 'a'), ('caring', 'n'), ('.', None), ('fine', 'a'), ('changing', 'v'), ('behave', 'a'), ('bothers', 'n'), ('people', 'n'), (',', None), ('got', 'v'), ('overwhelmed', 'a'), ('frustrated', 'a'), ('offensive', 'n'), ('.', None), ('feel', 'v'), ('unknowingly', 'r'), ('hurt', 'v'), (',', None), ('thought', 'v'), ('makes', 'v'), ('feel', 'n'), ('guilt', 'a'), ('makes', 'v'), ('feel', 'n'), ('enjoy', 'a'), ('life', 'n'), ('.', None), ('want', 'v'), ('courteous', 'a'), ('respect', 'a'), ('things', 'n'), ('bother', 'r'), ('/', 'a'), ('things', 'n'), (',', None), ('feel', 'v'), ('like', None), ('wearing', 'v'), ('constantly', 'r'), ('overthinking', 'v'), ('.', None)]\n",
            "Lemmatized Sentence empathetic person try kind love people , constantly worry right , thing enjoy way think / act offensive caring . fine change behave bother people , get overwhelmed frustrated offensive . feel unknowingly hurt , think make feel guilt make feel enjoy life . want courteous respect thing bother / thing , feel like wear constantly overthinking .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Positive/Negative Sentiment"
      ],
      "metadata": {
        "id": "nyBSZHW16y76"
      },
      "id": "nyBSZHW16y76"
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "# function to calculate subjectivity\n",
        "def getSubjectivity(review):\n",
        "    return TextBlob(review).sentiment.subjectivity\n",
        "\n",
        "# function to calculate polarity\n",
        "def getPolarity(review):\n",
        "    return TextBlob(review).sentiment.polarity\n",
        "\n",
        "# function to analyze the reviews\n",
        "def analysis(score):\n",
        "    if score < 0.10:\n",
        "        return 'Negative'\n",
        "    elif score == 0.10:\n",
        "        return 'Neutral'\n",
        "    else:\n",
        "        return 'Positive'"
      ],
      "metadata": {
        "id": "CSJQKosj54wg"
      },
      "id": "CSJQKosj54wg",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subjectivity = getSubjectivity(lemmatized_sentence)\n",
        "polarity = getPolarity(lemmatized_sentence)\n",
        "print(subjectivity)\n",
        "print(polarity)\n",
        "pscore= analysis(polarity)\n",
        "print(pscore)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqrlD17m6CyV",
        "outputId": "19b1eb2e-8264-4395-dda0-34c73e49c6ce"
      },
      "id": "IqrlD17m6CyV",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5402380952380953\n",
            "0.25023809523809526\n",
            "Positive\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
